{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:11.648579Z",
     "iopub.status.busy": "2025-03-18T19:28:11.648171Z",
     "iopub.status.idle": "2025-03-18T19:28:21.332763Z",
     "shell.execute_reply": "2025-03-18T19:28:21.325811Z",
     "shell.execute_reply.started": "2025-03-18T19:28:11.648544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imorting libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:26.475089Z",
     "iopub.status.busy": "2025-03-18T19:28:26.474696Z",
     "iopub.status.idle": "2025-03-18T19:28:26.479993Z",
     "shell.execute_reply": "2025-03-18T19:28:26.479242Z",
     "shell.execute_reply.started": "2025-03-18T19:28:26.475057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.models import vit_h_14\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:44:00.282418Z",
     "iopub.status.busy": "2025-03-18T19:44:00.282074Z",
     "iopub.status.idle": "2025-03-18T19:44:00.286131Z",
     "shell.execute_reply": "2025-03-18T19:44:00.285130Z",
     "shell.execute_reply.started": "2025-03-18T19:44:00.282386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Transformation\n",
    "- train_transform\n",
    "- val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:29.706823Z",
     "iopub.status.busy": "2025-03-18T19:28:29.706451Z",
     "iopub.status.idle": "2025-03-18T19:28:29.712758Z",
     "shell.execute_reply": "2025-03-18T19:28:29.712017Z",
     "shell.execute_reply.started": "2025-03-18T19:28:29.706791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train transformation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize([224], interpolation=InterpolationMode.BICUBIC),  # 384x384\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  \n",
    "    transforms.RandomVerticalFlip(p=0.5),  \n",
    "    transforms.RandomRotation(degrees=30),  \n",
    "    transforms.RandomCrop([224], padding=4),  \n",
    "    transforms.ColorJitter(\n",
    "    brightness=0.5,  \n",
    "    contrast=0.5,    \n",
    "    saturation=0.5,  \n",
    "    hue=0.1          \n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# Validation transformation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize([224], interpolation=InterpolationMode.BICUBIC), \n",
    "    transforms.CenterCrop([224]), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:36:06.733624Z",
     "iopub.status.busy": "2025-03-18T19:36:06.733333Z",
     "iopub.status.idle": "2025-03-18T19:36:10.542440Z",
     "shell.execute_reply": "2025-03-18T19:36:10.541784Z",
     "shell.execute_reply.started": "2025-03-18T19:36:06.733601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/\"\n",
    "entire_dataset = datasets.ImageFolder(dataset_path+'train', transform = train_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the data into validation and traning set ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:36:22.283825Z",
     "iopub.status.busy": "2025-03-18T19:36:22.283504Z",
     "iopub.status.idle": "2025-03-18T19:36:22.288671Z",
     "shell.execute_reply": "2025-03-18T19:36:22.287755Z",
     "shell.execute_reply.started": "2025-03-18T19:36:22.283801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size_fraction = 0.99\n",
    "train_size = int(train_size_fraction * len(entire_dataset))\n",
    "val_size = len(entire_dataset) - train_size\n",
    "train_dataset , val_dataset = random_split(entire_dataset , [train_size , val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:35.744063Z",
     "iopub.status.busy": "2025-03-18T19:28:35.743798Z",
     "iopub.status.idle": "2025-03-18T19:28:35.749499Z",
     "shell.execute_reply": "2025-03-18T19:28:35.748795Z",
     "shell.execute_reply.started": "2025-03-18T19:28:35.744040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "num_cpus = os.cpu_count()\n",
    "num_cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader with batch size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:54:57.856310Z",
     "iopub.status.busy": "2025-03-18T19:54:57.856003Z",
     "iopub.status.idle": "2025-03-18T19:54:57.860401Z",
     "shell.execute_reply": "2025-03-18T19:54:57.859714Z",
     "shell.execute_reply.started": "2025-03-18T19:54:57.856287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset , batch_size=16 , shuffle = True , num_workers=num_cpus )\n",
    "val_dataloader = DataLoader(val_dataset , batch_size=16 , shuffle = False , num_workers=num_cpus )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:44.023263Z",
     "iopub.status.busy": "2025-03-18T19:28:44.022935Z",
     "iopub.status.idle": "2025-03-18T19:28:55.530796Z",
     "shell.execute_reply": "2025-03-18T19:28:55.529579Z",
     "shell.execute_reply.started": "2025-03-18T19:28:44.023233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = models.vit_h_14(weights = models.ViT_H_14_Weights.IMAGENET1K_SWAG_LINEAR_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:28:59.400214Z",
     "iopub.status.busy": "2025-03-18T19:28:59.399904Z",
     "iopub.status.idle": "2025-03-18T19:28:59.414761Z",
     "shell.execute_reply": "2025-03-18T19:28:59.413937Z",
     "shell.execute_reply.started": "2025-03-18T19:28:59.400192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.heads = nn.Sequential(\n",
    "    nn.Linear(in_features=1280 , out_features = 128, bias = True ),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear( in_features = 128 , out_features = 10 , bias = True )\n",
    "    )\n",
    "for param in model.heads.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.encoder.layers.encoder_layer_31.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:29:02.435235Z",
     "iopub.status.busy": "2025-03-18T19:29:02.434921Z",
     "iopub.status.idle": "2025-03-18T19:29:03.376679Z",
     "shell.execute_reply": "2025-03-18T19:29:03.375601Z",
     "shell.execute_reply.started": "2025-03-18T19:29:02.435210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using(GPU's) {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  # Wraping model for multi-GPU support\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:29:06.261558Z",
     "iopub.status.busy": "2025-03-18T19:29:06.261244Z",
     "iopub.status.idle": "2025-03-18T19:29:06.268044Z",
     "shell.execute_reply": "2025-03-18T19:29:06.266984Z",
     "shell.execute_reply.started": "2025-03-18T19:29:06.261534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:43:54.629701Z",
     "iopub.status.busy": "2025-03-18T19:43:54.629363Z",
     "iopub.status.idle": "2025-03-18T19:43:54.637125Z",
     "shell.execute_reply": "2025-03-18T19:43:54.636263Z",
     "shell.execute_reply.started": "2025-03-18T19:43:54.629675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval() \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validating Model\", total=len(dataloader)):\n",
    "            # Move inputs and labels to the specified device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Get predicted class indices\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Get probabilities (for AUC-ROC in multiclass)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Keep all class probabilities\n",
    "\n",
    "            # Accumulate predictions, labels, and probabilities\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "\n",
    "    # Concatenate all predictions, labels, and probabilities into single tensors\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "\n",
    "    # Convert to numpy arrays for sklearn\n",
    "    all_preds_np = all_preds.numpy()\n",
    "    all_labels_np = all_labels.numpy()\n",
    "    all_probs_np = all_probs.numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels_np, all_preds_np)\n",
    "    f1 = f1_score(all_labels_np, all_preds_np, average=\"macro\")\n",
    "    precision = precision_score(all_labels_np, all_preds_np, average=\"macro\")\n",
    "    recall = recall_score(all_labels_np, all_preds_np, average=\"macro\")\n",
    "\n",
    "    # ✅ Updated AUC-ROC Calculation (For Multiclass)\n",
    "    auc_roc = roc_auc_score(all_labels_np, all_probs_np, multi_class='ovr', average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc_roc\": auc_roc\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T19:55:02.849405Z",
     "iopub.status.busy": "2025-03-18T19:55:02.849108Z",
     "iopub.status.idle": "2025-03-18T20:36:06.147967Z",
     "shell.execute_reply": "2025-03-18T20:36:06.146877Z",
     "shell.execute_reply.started": "2025-03-18T19:55:02.849383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "scaler = GradScaler()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Directory to save checkpoints\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_accuracy = 0.0  # Track best accuracy\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0\n",
    "    with tqdm(train_dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", unit=\"batch\") as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass with scaled gradients\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({\"loss\": f\"{train_loss/len(train_dataloader):.4f}\"})\n",
    "    \n",
    "    # Evaluate the model after each epoch\n",
    "    metrics = evaluate_model(model, val_dataloader, device)\n",
    "    accuracy = metrics[\"accuracy\"]\n",
    "    f1 = metrics[\"f1_score\"]\n",
    "    auc_roc = metrics[\"auc_roc\"]\n",
    "    print(f\"Epoch {epoch+1} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f} , AUC_ROC: {auc_roc:.4f}\")\n",
    "\n",
    "    # Save best model based on accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_checkpoint_path = os.path.join(checkpoint_dir, \"best_checkpoint.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'loss': train_loss / len(train_dataloader),\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "        }, best_checkpoint_path)\n",
    "        print(f\"Best model saved with accuracy: {best_accuracy:.4f} at {best_checkpoint_path}\")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(f\"Best accuracy achieved: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting in test dataset and saving the submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T20:36:06.149772Z",
     "iopub.status.busy": "2025-03-18T20:36:06.149398Z",
     "iopub.status.idle": "2025-03-18T20:36:06.162377Z",
     "shell.execute_reply": "2025-03-18T20:36:06.161218Z",
     "shell.execute_reply.started": "2025-03-18T20:36:06.149722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def classify_images_to_csv(image_folder, model, transform, output_csv):\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare a list to store results\n",
    "    results = []\n",
    "\n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    total = len(image_files)\n",
    "\n",
    "    # Process each image in the folder with tqdm progress bar\n",
    "    for image_name in tqdm(image_files, desc=\"Processing Images\", total=total):\n",
    "        # Read and preprocess the image\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)  # Get raw outputs\n",
    "            probabilities = torch.softmax(outputs, dim=1)  # Apply softmax\n",
    "            label = torch.argmax(probabilities, dim=1).item()  # Get the predicted label\n",
    "\n",
    "        # Store the result\n",
    "        results.append({\n",
    "            \"Image_ID\": image_name.split('.')[0],\n",
    "            \"Label\": label\n",
    "        })\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T20:36:06.164588Z",
     "iopub.status.busy": "2025-03-18T20:36:06.164231Z",
     "iopub.status.idle": "2025-03-18T20:42:15.865639Z",
     "shell.execute_reply": "2025-03-18T20:42:15.864958Z",
     "shell.execute_reply.started": "2025-03-18T20:36:06.164550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best checkpoint\n",
    "best_checkpoint_path = \"./checkpoints/best_checkpoint.pth\"\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location=device)\n",
    "\n",
    "# Load model state dict\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "classify_images_to_csv('/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/test',model,val_transform,\"/kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11298874,
     "sourceId": 95041,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
